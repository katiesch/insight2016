{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import sklearn\n",
    "import datetime\n",
    "import array \n",
    "import math\n",
    "\n",
    "import shapefile as sf\n",
    "from matplotlib.patches import Polygon\n",
    "import mpld3\n",
    "\n",
    "from censusgeocode import CensusGeocode\n",
    "from matplotlib.collections import PatchCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def whichshape(lat,lon,path):\n",
    "    sr = sf.Reader(path)\n",
    "    shapes = sr.shapes()\n",
    "    for i in range(len(shapes)):\n",
    "        if inshape(lat,lon,shapes[i]):\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inshape(ptlat,ptlon,shape):\n",
    "    # does not behave well near poles!!!\n",
    "    pts = shape.points\n",
    "    lat=[]\n",
    "    lon=[]\n",
    "    for pt in pts:\n",
    "        lat.append(pt[1])\n",
    "        lon.append(pt[0])\n",
    "    lon_max=max(lon)\n",
    "    lon_min=min(lon)\n",
    "    lat_max=max(lat)\n",
    "    lat_min=min(lat)\n",
    "    \n",
    "    if lon_min < -170 and lon_max > 170:\n",
    "        for i in range(len(pts)):\n",
    "            if pts[i][0]<0:\n",
    "                pts[i][0] = 360+pts[i]\n",
    "    \n",
    "    if (ptlat > lat_max or ptlat < lat_min or\n",
    "        ptlon > lon_max or ptlon < lon_min):\n",
    "        return 0\n",
    "    else:\n",
    "        count = 0\n",
    "        for i in range(len(pts)-1):\n",
    "            line=[pts[i][0],pts[i][1],\n",
    "                  pts[i+1][0],pts[i+1][1]]\n",
    "                  \n",
    "            if ((line[1] < ptlat and line[3] > ptlat) or \n",
    "                (line[1] > ptlat and line[3] < ptlat)):\n",
    "               frac = (line[1]-ptlat)/(line[1]-line[3])\n",
    "               if line[0]+frac*(line[2]-line[0]) > ptlon:\n",
    "                    count+=1\n",
    "        \n",
    "        line=[pts[-1][0],pts[0][1],\n",
    "              pts[-1][0],pts[0][1]]                  \n",
    "        if line[1] < ptlat and line[3] > ptlat:\n",
    "           frac = (line[1]-ptlat)/(line[1]-line[3])\n",
    "           if line[0]+frac*(line[2]-line[0]) > ptlon:\n",
    "                count+=1\n",
    "\n",
    "    return count%2         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 311 Request files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kschles/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (0,17,19,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "requests = pd.read_csv('DataforInsight.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Problem Category</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Over Irrigation</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parking Meter</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Damaged Guardrail</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Street Flooded</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dead Animal</th>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Faded striping</th>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Street Sweeping</th>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Storm Drain</th>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tree Hazard</th>\n",
       "      <td>752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Curb</th>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traffic Sign</th>\n",
       "      <td>930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traffic Signal</th>\n",
       "      <td>1153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abandoned Vehicle</th>\n",
       "      <td>1252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sidewalk</th>\n",
       "      <td>1296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Street Light</th>\n",
       "      <td>1515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Litter/Dumping</th>\n",
       "      <td>1665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pothole</th>\n",
       "      <td>2423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Graffiti</th>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>3735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Case Number\n",
       "Problem Category              \n",
       "Over Irrigation              1\n",
       "Parking Meter               34\n",
       "Damaged Guardrail           61\n",
       "Street Flooded             100\n",
       "Dead Animal                122\n",
       "Faded striping             193\n",
       "Street Sweeping            258\n",
       "Storm Drain                274\n",
       "Tree Hazard                752\n",
       "Curb                       883\n",
       "Traffic Sign               930\n",
       "Traffic Signal            1153\n",
       "Abandoned Vehicle         1252\n",
       "Sidewalk                  1296\n",
       "Street Light              1515\n",
       "Litter/Dumping            1665\n",
       "Pothole                   2423\n",
       "Graffiti                  3600\n",
       "Other                     3735"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests[['Problem Category', 'Case Number']].groupby('Problem Category').count().sort_values(by='Case Number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolate requests of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graffiti = requests.loc[np.where(requests['Problem Category']=='Graffiti')[0]]\n",
    "graffiti.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dump = requests.loc[np.where(requests['Problem Category']=='Litter/Dumping')[0]]\n",
    "dump.reset_index(drop=True, inplace=True)\n",
    "\n",
    "lighting = requests.loc[np.where(requests['Problem Category']=='Street Light')[0]]\n",
    "lighting.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Census linking information for request locations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cg = CensusGeocode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "requests['block']=None\n",
    "requests['tract']=None\n",
    "requests['geoid']=None\n",
    "requests['blockgroup']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13200 0:01:17.631727\n",
      "13300 0:01:02.481330\n",
      "13400 0:01:12.625485\n",
      "13500 0:01:18.448509\n",
      "13600 0:01:03.096039\n",
      "13700 0:01:17.490964\n",
      "13800 0:01:22.407940\n",
      "13900 0:01:02.041980\n",
      "14000 0:01:08.443168\n",
      "14100 0:01:09.428046\n",
      "14200 0:01:07.492265\n",
      "14300 0:00:56.761278\n",
      "14400 0:01:13.255247\n",
      "14500 0:01:12.487709\n",
      "14600 0:01:24.316358\n",
      "14700 0:01:07.770941\n",
      "14800 0:01:24.572345\n",
      "14900 0:01:09.458441\n",
      "15000 0:01:03.182257\n",
      "15100 0:01:02.565870\n",
      "15200 0:01:02.951913\n",
      "15300 0:01:28.528602\n",
      "15400 0:00:57.778108\n",
      "15500 0:00:57.970770\n",
      "15600 0:01:21.884530\n",
      "15700 0:01:18.255734\n",
      "15800 0:01:03.000292\n",
      "15900 0:01:08.006805\n",
      "16000 0:01:01.867869\n",
      "16100 0:01:02.033723\n",
      "16200 0:01:14.390271\n",
      "16300 0:01:02.519959\n",
      "16400 0:01:18.055804\n",
      "16500 0:01:07.159415\n",
      "16600 0:01:07.483389\n",
      "16700 0:01:17.849506\n",
      "16800 0:01:06.354572\n",
      "16900 0:01:25.211410\n",
      "17000 0:01:09.805353\n",
      "17100 0:01:18.925729\n",
      "17200 0:01:03.003951\n",
      "17300 0:01:08.916376\n",
      "17400 0:01:08.429254\n",
      "17500 0:01:22.755352\n",
      "17600 0:01:12.540263\n",
      "17700 0:01:08.728271\n",
      "17800 0:01:13.355258\n",
      "17900 0:01:20.514310\n",
      "18000 0:01:18.631790\n",
      "18100 0:01:27.269506\n",
      "18200 0:01:15.451264\n",
      "18300 0:01:22.705418\n",
      "18400 0:01:17.864192\n",
      "18500 0:01:18.537731\n",
      "18600 0:01:14.773337\n",
      "18700 0:01:43.554035\n",
      "18800 0:01:24.273641\n",
      "18900 0:01:13.144794\n",
      "19000 0:01:18.273014\n",
      "19100 0:01:35.665891\n",
      "19200 0:01:07.731839\n",
      "19300 0:01:13.170830\n",
      "19400 0:01:17.770835\n",
      "19500 0:01:29.764675\n",
      "19600 0:01:27.261241\n",
      "19700 0:01:09.440455\n",
      "19800 0:01:17.869570\n",
      "19900 0:01:07.821059\n",
      "20000 0:01:23.350558\n",
      "20100 0:01:13.029347\n",
      "20200 0:01:18.896044\n",
      "20300 0:01:14.664722\n",
      "20400 0:01:13.599806\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "for i in range(0,len(requests)): \n",
    "    if ((requests.loc[i,'Geolocation (Longitude)']!=0.0) \n",
    "        & (np.isnan(requests.loc[i,'Geolocation (Longitude)'])==False)) :\n",
    "        temp1 = cg.coordinates(x=requests.loc[i,'Geolocation (Longitude)'], \n",
    "                              y=requests.loc[i, 'Geolocation (Latitude)'])\n",
    "        if (len(temp1[0]['2010 Census Blocks'])>0):\n",
    "            if ('status' not in temp1[0]['2010 Census Blocks'][0].keys()[0]): \n",
    "                temp = temp1[0]['2010 Census Blocks'][0]\n",
    "                if (temp is not None):\n",
    "                    requests.loc[i, 'block'] = temp['BLOCK']\n",
    "                    requests.loc[i, 'tract'] = temp['TRACT']\n",
    "                    requests.loc[i, 'geoid'] = temp['GEOID']\n",
    "                    requests.loc[i, 'blockgroup'] = temp['BLKGRP']\n",
    "\n",
    "                if (i % 100 == 0): \n",
    "                    finish = datetime.datetime.now()\n",
    "                    print i, finish-start\n",
    "                    start = datetime.datetime.now()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kschles/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (0,17,19,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Once all the geocodes are done, output the file as requests_processed_start.csv: \n",
    "#requests.to_csv('output_files/requests_processed_start.csv', index=False)\n",
    "requests = pd.read_csv('output_files/requests_processed_start.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove Duplicate requests\n",
    "requests.columns.values\n",
    "\n",
    "requests_unique = requests.loc[np.where(requests['Duplicate Verified']==0.0)[0]]\n",
    "requests_unique.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count up graffiti reports\n",
    "requests_unique['graffiti_count'] = 0.0\n",
    "\n",
    "requests_unique.loc[np.where(requests_unique['Problem Category']=='Graffiti')[0], \n",
    "                    'graffiti_count'] = 1.0\n",
    "\n",
    "# Count up dumping reports\n",
    "requests_unique['dump_count'] = 0.0\n",
    "\n",
    "requests_unique.loc[np.where(requests_unique['Problem Category']=='Litter/Dumping')[0], \n",
    "                    'dump_count'] = 1.0\n",
    "\n",
    "# Count up street light reports\n",
    "requests_unique['lighting_count'] = 0.0\n",
    "\n",
    "requests_unique.loc[np.where(requests_unique['Problem Category']=='Street Light')[0], \n",
    "                    'lighting_count'] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For graffiti and dumping reports, calculate the distance from the nearest streetlight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sl_record = pd.read_csv('output_files/streetlight_latlon.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each event, I want to calculate the minimum distance from a street light. \n",
    "Only doing this for graffiti and dumping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "requests_unique['sl_mindist'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(requests_unique)): \n",
    "    if ((requests_unique.loc[i,'Problem Category']=='Graffiti') \n",
    "        | (requests_unique.loc[i, 'Problem Category']=='Litter/Dumping')): \n",
    "        lat1=requests_unique.loc[i, 'Geolocation (Latitude)']\n",
    "        lon1=requests_unique.loc[i, 'Geolocation (Longitude)']\n",
    "\n",
    "        R = 6371 * 3280.84 # feet\n",
    "\n",
    "        dLat = np.radians(np.array(np.array(sl_record['lat']) - lat1).astype(float))\n",
    "        dLon = np.radians(np.array(np.array(sl_record['lon']) - lon1).astype(float))\n",
    "        lat_source = np.radians(lat1)\n",
    "        lat_comp = np.radians(np.array(sl_record['lat']).astype(float))\n",
    "\n",
    "\n",
    "        a = np.sin(dLat/2.0) * np.sin(dLat/2.0) + np.sin(dLon/2.0) * np.sin(dLon/2.0) * np.cos(lat_source) * np.cos(lat_comp) \n",
    "        c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "        d = R * c\n",
    "\n",
    "        requests_unique.loc[i, 'sl_mindist'] = float(d[np.argmin(d)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "requests_unique['sl_mindist'] = requests_unique['sl_mindist'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the file that keeps track of the individual request informations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#requests_unique.to_csv('output_files/requests_processed_0917.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kschles/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (17,19,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "requests_unique = pd.read_csv('output_files/requests_processed_0917.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have things organised for individual requests. We also want to organise the requests by their block groups. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, organise the individual requests by block group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "requests_unique['count'] = 1.0\n",
    "total_reports = requests_unique[['tract', 'blockgroup', 'count', \n",
    "                                 'graffiti_count','dump_count', \n",
    "                                 'lighting_count']].groupby(['tract', 'blockgroup'], as_index=False).agg('sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to break it up by how the 311 reports came in as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mobile = requests_unique.loc[np.where(requests_unique['Case Origin']=='Mobile')[0], ['tract','blockgroup',\n",
    "                                                               'Case Origin']]\n",
    "web = requests_unique.loc[np.where(requests_unique['Case Origin']=='Web')[0], ['tract','blockgroup',\n",
    "                                                               'Case Origin']]\n",
    "phone = requests_unique.loc[np.where(requests_unique['Case Origin']=='Phone')[0], ['tract','blockgroup',\n",
    "                                                               'Case Origin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mobile_counts = mobile.groupby(['tract', 'blockgroup'], as_index=False).agg('count')\n",
    "mobile_counts.rename(columns={'Case Origin': 'mobile_counts'}, inplace=True)\n",
    "\n",
    "web_counts = web.groupby(['tract', 'blockgroup'], as_index=False).agg('count')\n",
    "web_counts.rename(columns={'Case Origin': 'web_counts'}, inplace=True)\n",
    "\n",
    "phone_counts = phone.groupby(['tract', 'blockgroup'], as_index=False).agg('count')\n",
    "phone_counts.rename(columns={'Case Origin': 'phone_counts'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp1 = pd.merge(total_reports, mobile_counts, on=['tract', 'blockgroup'], how='left')\n",
    "temp2 = pd.merge(temp1, web_counts, on=['tract', 'blockgroup'], how='left')\n",
    "total_reports = pd.merge(temp2, phone_counts, on=['tract', 'blockgroup'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to combine with the street light information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, calculate the mean distance from a street light \n",
    "# for different events organised by blockgroup. \n",
    "# Mean sl_dist for each census track, block group \n",
    "graffiti_distance = requests_unique.loc[np.where(requests_unique['Problem Category']=='Graffiti')[0],\n",
    "                                        ['tract', 'blockgroup', 'sl_mindist']].groupby(['tract', \n",
    "                                                                                        'blockgroup'], as_index=False).agg('mean')\n",
    "\n",
    "\n",
    "dump_distance = requests_unique.loc[np.where(requests_unique['Problem Category']=='Litter/Dumping')[0],\n",
    "                                        ['tract', 'blockgroup', 'sl_mindist']].groupby(['tract', \n",
    "                                                                                        'blockgroup'], as_index=False).agg('mean')\n",
    "\n",
    "#response_time = requests_unique.loc[np.where(requests_unique['Problem Category']=='Graffiti')[0],\n",
    "#                                        ['tract', 'blockgroup', 'Age (Days)', 'count']].groupby(['tract', \n",
    "#                                                                                        'blockgroup'], as_index=False).agg({'count' :'sum','sl_mindist': 'mean'})\n",
    "\n",
    "graffiti_distance.rename(columns={'sl_mindist': 'gsl_meandist'}, inplace=True)\n",
    "dump_distance.rename(columns={'sl_mindist': 'dsl_meandist'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, calculate the mean distance from a street light \n",
    "# for different events organised by blockgroup. \n",
    "# Mean sl_dist for each census track, block group \n",
    "graffiti_distance1 = requests_unique.loc[np.where(requests_unique['Problem Category']=='Graffiti')[0],\n",
    "                                        ['tract', 'blockgroup', 'sl_mindist', 'count']].groupby(['tract', \n",
    "                                                                                        'blockgroup'], as_index=False).agg({'count' :'sum','sl_mindist': 'mean'})\n",
    "\n",
    "dump_distance1 = requests_unique.loc[np.where(requests_unique['Problem Category']=='Litter/Dumping')[0],\n",
    "                                        ['tract', 'blockgroup', 'sl_mindist', 'count']].groupby(['tract', \n",
    "                                                                                        'blockgroup'], as_index=False).agg({'count' :'sum','sl_mindist': 'mean'})\n",
    "\n",
    "#response_time1 = requests_unique.loc[np.where(requests_unique['Problem Category']=='Graffiti')[0],\n",
    "#                                        ['tract', 'blockgroup', 'Age (Days)', 'count']].groupby(['tract', \n",
    "#                                                                                        'blockgroup'], as_index=False).agg('std')\n",
    "\n",
    "graffiti_distance1.rename(columns={'sl_mindist': 'gsl_stddist'}, inplace=True)\n",
    "dump_distance1.rename(columns={'sl_mindist': 'dsl_stddist'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, calculate the mean distance from a street light \n",
    "# for different events organised by blockgroup. \n",
    "# Mean sl_dist for each census track, block group \n",
    "graffiti_distance2 = requests_unique.loc[np.where(requests_unique['Problem Category']=='Graffiti')[0],\n",
    "                                        ['tract', 'blockgroup', 'sl_mindist']].groupby(['tract', \n",
    "                                                                                        'blockgroup'], as_index=False).agg('median')\n",
    "\n",
    "dump_distance2 = requests_unique.loc[np.where(requests_unique['Problem Category']=='Litter/Dumping')[0],\n",
    "                                        ['tract', 'blockgroup', 'sl_mindist']].groupby(['tract', \n",
    "                                                                                        'blockgroup'], as_index=False).agg('median')\n",
    "\n",
    "response_time2 = requests_unique.loc[np.where(requests_unique['Problem Category']=='Graffiti')[0],\n",
    "                                        ['tract', 'blockgroup', 'Age (Days)']].groupby(['tract', \n",
    "                                                                                        'blockgroup'], as_index=False).agg('median')\n",
    "\n",
    "graffiti_distance2.rename(columns={'sl_mindist': 'gsl_mediandist'}, inplace=True)\n",
    "dump_distance2.rename(columns={'sl_mindist': 'dsl_mediandist'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge with minimum distance information: \n",
    "temp1 = pd.merge(total_reports, graffiti_distance, on=['tract', 'blockgroup'], \n",
    "                 how='left')\n",
    "temp2 = pd.merge(temp1, graffiti_distance1[['tract', 'blockgroup', 'gsl_stddist']], on=['tract', 'blockgroup'], \n",
    "                 how='left')\n",
    "temp3 = pd.merge(temp2, graffiti_distance2, on=['tract', 'blockgroup'], \n",
    "                 how='left')\n",
    "\n",
    "temp4 = pd.merge(temp3, dump_distance, on=['tract', 'blockgroup'], \n",
    "                 how='left')\n",
    "temp5 = pd.merge(temp4, dump_distance1[['tract', 'blockgroup', 'dsl_stddist']], on=['tract', 'blockgroup'], \n",
    "                 how='left')\n",
    "total_reports = pd.merge(temp5, dump_distance2, on=['tract', 'blockgroup'], \n",
    "                         how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tract', 'blockgroup', 'count', 'graffiti_count', 'dump_count',\n",
       "       'lighting_count', 'mobile_counts', 'web_counts', 'phone_counts',\n",
       "       'gsl_meandist', 'gsl_stddist', 'gsl_mediandist', 'dsl_meandist',\n",
       "       'dsl_stddist', 'dsl_mediandist'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_reports.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge with information about street light density and street light counts\n",
    "sl_info = pd.read_csv('output_files/streetlight_density.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sl_info['tract'] = sl_info['tract'].astype(float)\n",
    "sl_info['blockgroup'] = sl_info['blockgroup'].astype(float)\n",
    "sl_info.rename(columns={'count': 'sl_count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reports_sl = pd.merge(total_reports, sl_info, on=['tract', 'blockgroup'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now I have all the reports broken down by block group. However, not all of them are in San Diego county. Need to trim things down appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Blockgroup shape file\n",
    "reader = sf.Reader('shapefiles/tl_2016_06_bg/tl_2016_06_bg.shp')\n",
    "bg_info = pd.DataFrame(reader.records())\n",
    "shapes = reader.shapes()\n",
    "\n",
    "# the San Diego county shapefile records\n",
    "sdcounty = bg_info.loc[np.where((bg_info[1]=='073') & (bg_info[3]!='0'))[0]]\n",
    "sdcounty_index = np.where((bg_info[1]=='073') & (bg_info[3]!='0'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23212, 1794)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bg_info), len(sdcounty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sdcounty['tract'] = sdcounty[2].astype(float)\n",
    "sdcounty['blockgroup'] = sdcounty[3].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sdcounty_only_requests = pd.merge(sdcounty[['tract','blockgroup']], reports_sl, \n",
    "                                  on=['tract', 'blockgroup'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Output as a CSV\n",
    "#sdcounty_only_requests.to_csv('output_files/sdcounty_only_requests_0917.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now I have all the info I need sorted by block group\n",
    "\n",
    "I now need to combine with some census information to get the rest of the detailed columns I need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 33 33\n",
      "4 4 4\n"
     ]
    }
   ],
   "source": [
    "## Want to match report numbers with Census information about the total people in a given area\n",
    "\n",
    "filenames='aff/block_groups/*with_ann.csv'\n",
    "test=glob.glob(filenames)\n",
    "\n",
    "all_of_interest = [33, 4]\n",
    "\n",
    "for i in all_of_interest: \n",
    "    temp = pd.read_csv(test[i], header=1, low_memory=False)\n",
    "    print i, i, i \n",
    "    if (i==33): \n",
    "        census = temp.copy()\n",
    "    if (i!=33): \n",
    "        combo = pd.merge(census, temp, on='Id', how='left', suffixes=('', '_' + str(i)))\n",
    "        census = combo.copy()\n",
    "        census.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "census_trimmed = census[['GEOGRAPHIC AREA CODES - Census Tract',\n",
    "                         'GEOGRAPHIC AREA CODES - Block Group',\n",
    "                         'Estimate; Total']].copy()\n",
    "\n",
    "census_trimmed.rename(columns={'GEOGRAPHIC AREA CODES - Census Tract': 'tract', \n",
    "                               'GEOGRAPHIC AREA CODES - Block Group': 'blockgroup'}, \n",
    "                      inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge report numbers with population estimates\n",
    "total_reports_demo = pd.merge(sdcounty_only_requests, \n",
    "                              census_trimmed, on=['tract', 'blockgroup'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Currently set to NaN when there are no counts. Change to 0. \n",
    "total_reports_demo.loc[np.where(np.isnan(total_reports_demo['count'])==True)[0], 'count'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reports per capita\n",
    "total_reports_demo['rep_per_cap'] = (total_reports_demo['count'] \n",
    "                                     / total_reports_demo['Estimate; Total'])\n",
    "\n",
    "# Percentage of reports in each category\n",
    "total_reports_demo['graffiti_per'] = (total_reports_demo['graffiti_count'] \n",
    "                                      / total_reports_demo['count'])\n",
    "total_reports_demo['dump_per'] = (total_reports_demo['dump_count'] \n",
    "                                  / total_reports_demo['count'])\n",
    "total_reports_demo['lighting_per'] = (total_reports_demo['lighting_count'] \n",
    "                                      / total_reports_demo['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_reports_demo.rename(columns={'Estimate; Total': 'total_pop'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I have processed all of the information county-wide. But now I want to identify items that are in San Diego city proper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in Jeff's list of census tracts in SD city proper \n",
    "sd_city_proper = pd.read_csv('SD_city_census_tracts.txt')\n",
    "\n",
    "sd_city_proper['tract'] = sd_city_proper['tract'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the edited list i made of block groups that are in municipal-range census tracts, \n",
    "# but not within the city itself\n",
    "sd_bg_edited = pd.read_csv('tract_blockgroups_to_ignore.csv')\n",
    "sd_bg_edited['blockgroup'] = sd_bg_edited['blockgroup'].astype(float)\n",
    "sd_bg_edited['tract'] = sd_bg_edited['tract'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_reports_demo['tract_in_city'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(total_reports_demo)): \n",
    "    temp_tract = total_reports_demo.loc[i, 'tract']\n",
    "    temp_bg = total_reports_demo.loc[i, 'blockgroup']\n",
    "    if (len(np.where(sd_city_proper['tract']==temp_tract)[0])>0):\n",
    "        if (len(np.where((sd_bg_edited['tract']==temp_tract) \n",
    "                         & (sd_bg_edited['blockgroup']==temp_bg))[0])==0):        \n",
    "            total_reports_demo.loc[i, 'tract_in_city'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In city proper: 836\n",
      "Outside city proper: 958\n"
     ]
    }
   ],
   "source": [
    "print 'In city proper:', len(np.where(total_reports_demo['tract_in_city']==1.0)[0]) \n",
    "print 'Outside city proper:', len(np.where(total_reports_demo['tract_in_city']==0.0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Output the reports organised by block group \n",
    "total_reports_demo.to_csv('output_files/total_reports_demo_0917.csv', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tract', 'blockgroup', 'count', 'graffiti_count', 'dump_count',\n",
       "       'lighting_count', 'gsl_meandist', 'gsl_stddist', 'gsl_mediandist',\n",
       "       'dsl_meandist', 'dsl_stddist', 'dsl_mediandist', 'sl_count',\n",
       "       'landarea', 'cent_lat', 'cent_lon', 'sl_density', 'total_pop',\n",
       "       'rep_per_cap', 'graffiti_per', 'dump_per', 'lighting_per',\n",
       "       'tract_in_city'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_reports_demo.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Tim's code instead of geocoder:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes Census geocoder is down. This allows you to match each object with a shapefile region instead. It's a bit slower. Trim shapefile down to San Diego County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = sf.Reader('shapefiles/tl_2016_06_bg/tl_2016_06_bg.shp')\n",
    "w = sf.Writer(shapeType=sf.POLYGON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy the fields to the writer\n",
    "w.fields = list(r.fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grab the geometry and records from all features \n",
    "# with the correct county name \n",
    "selection = [] \n",
    "for rec in enumerate(r.records()):\n",
    "    if ((rec[1][1]=='073') & (rec[1][3]!='0')):\n",
    "          selection.append(rec) \n",
    "# Add the geometry and records to the writer\n",
    "\n",
    "for rec in selection:\n",
    "    w._shapes.append(r.shape(rec[0]))\n",
    "    w.records.append(rec[1])\n",
    "# Save the new shapefile\n",
    "w.save(\"shapefiles/sandiego_county_blockgroups\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match each 311 report with it's associated block group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0:00:00.920797\n",
      "100 0:01:41.484810\n",
      "200 0:01:38.798607\n",
      "300 0:01:41.140341\n",
      "400 0:01:44.568110\n",
      "500 0:01:42.041521\n",
      "600 0:01:42.453154\n",
      "700 0:01:42.134142\n",
      "800 0:01:43.106106\n",
      "900 0:01:42.113004\n",
      "1000 0:01:41.735002\n",
      "1100 0:01:41.449113\n",
      "1200 0:01:40.819706\n",
      "1300 0:01:43.134757\n"
     ]
    }
   ],
   "source": [
    "temporary = lighting \n",
    "\n",
    "temporary['block_group']=None\n",
    "temporary['tract']=None\n",
    "temporary['geoid']=None\n",
    "\n",
    "reading = sf.Reader('shapefiles/sandiego_county_blockgroups.shp')\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "for i in range(0,len(lighting)): \n",
    "    if (temporary.loc[i,'Geolocation (Longitude)']!=0.0) :\n",
    "        temp = whichshape(temporary.loc[i,'Geolocation (Latitude)'], \n",
    "                          temporary.loc[i, 'Geolocation (Longitude)'], \n",
    "                          'shapefiles/sandiego_county_blockgroups.shp')\n",
    "        if (temp is not None):\n",
    "            temporary.loc[i, 'block_group'] = reading.records()[temp][3]\n",
    "            temporary.loc[i, 'tract'] = reading.records()[temp][2]\n",
    "            temporary.loc[i, 'geoid'] = reading.records()[temp][4]\n",
    "        \n",
    "    if (i % 100 == 0): \n",
    "        finish = datetime.datetime.now()\n",
    "        print i, finish-start\n",
    "        start = datetime.datetime.now()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
